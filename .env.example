# =============================================================================
# 内部統制テスト評価AIシステム - 環境変数設定
# =============================================================================
# このファイルを .env にコピーして、実際の値を設定してください。
# cp .env.example .env
#
# 注意: .env ファイルは .gitignore に含まれており、Gitにコミットされません。
# =============================================================================

# =============================================================================
# LLM Provider Configuration
# =============================================================================
# Choose one: AZURE_FOUNDRY, AZURE, GCP, or AWS
LLM_PROVIDER=AZURE_FOUNDRY

# -----------------------------------------------------------------------------
# Azure AI Foundry (Recommended for Azure users)
# -----------------------------------------------------------------------------
# Set LLM_PROVIDER=AZURE_FOUNDRY to use these settings
AZURE_FOUNDRY_ENDPOINT=https://your-project.region.models.ai.azure.com
AZURE_FOUNDRY_API_KEY=your-foundry-api-key
AZURE_FOUNDRY_MODEL=gpt-4o
# Optional: API version (default: 2024-08-01-preview)
# AZURE_FOUNDRY_API_VERSION=2024-08-01-preview

# -----------------------------------------------------------------------------
# Azure OpenAI Service
# -----------------------------------------------------------------------------
# Set LLM_PROVIDER=AZURE to use these settings
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
# AZURE_OPENAI_API_KEY=your-azure-openai-api-key
# AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o

# -----------------------------------------------------------------------------
# GCP Vertex AI
# -----------------------------------------------------------------------------
# Set LLM_PROVIDER=GCP to use these settings
# Authentication: Use GOOGLE_APPLICATION_CREDENTIALS or Application Default Credentials
# GCP_PROJECT_ID=your-gcp-project-id
# GCP_LOCATION=us-central1
# GCP_MODEL_NAME=gemini-1.5-pro

# -----------------------------------------------------------------------------
# AWS Bedrock
# -----------------------------------------------------------------------------
# Set LLM_PROVIDER=AWS to use these settings
# Authentication: Use IAM role (Lambda) or access keys
# AWS_REGION=us-east-1
# AWS_ACCESS_KEY_ID=your-access-key-id
# AWS_SECRET_ACCESS_KEY=your-secret-access-key
# AWS_BEDROCK_MODEL_ID=anthropic.claude-3-sonnet-20240229-v1:0

# =============================================================================
# OCR Provider Configuration
# =============================================================================
# Choose one: AZURE, AWS, GCP, TESSERACT, or NONE
# If NONE or not set, falls back to pypdf (text-based PDF only)
OCR_PROVIDER=AZURE

# -----------------------------------------------------------------------------
# Azure Document Intelligence
# -----------------------------------------------------------------------------
# Set OCR_PROVIDER=AZURE to use these settings
AZURE_DI_ENDPOINT=https://your-resource.cognitiveservices.azure.com/
AZURE_DI_KEY=your-document-intelligence-key

# -----------------------------------------------------------------------------
# AWS Textract
# -----------------------------------------------------------------------------
# Set OCR_PROVIDER=AWS to use these settings
# Uses same AWS credentials as LLM provider
# AWS_TEXTRACT_REGION=ap-northeast-1

# -----------------------------------------------------------------------------
# GCP Document AI
# -----------------------------------------------------------------------------
# Set OCR_PROVIDER=GCP to use these settings
# GCP_DOCAI_PROJECT_ID=your-project-id
# GCP_DOCAI_LOCATION=us
# GCP_DOCAI_PROCESSOR_ID=your-processor-id

# -----------------------------------------------------------------------------
# Tesseract OCR (Local/OSS)
# -----------------------------------------------------------------------------
# Set OCR_PROVIDER=TESSERACT to use these settings
# TESSERACT_CMD=tesseract
# TESSERACT_LANG=jpn+eng

# =============================================================================
# Orchestrator Configuration
# =============================================================================
# Enable LangGraph-based orchestrator with self-reflection
# Set to "false" to use the simple AuditOrchestrator
USE_GRAPH_ORCHESTRATOR=true
